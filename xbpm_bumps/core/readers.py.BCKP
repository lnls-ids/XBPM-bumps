"""Data reading from files and pickle directories."""

import os
import re
import sys
import logging
import numpy as np
from typing import Optional

# Reading trusted local experiment data; HDF5 path will replace this
import pickle  # noqa: S403

from .config import Config
from .parameters import Prm, ParameterBuilder
from .processors import XBPMProcessor


logger = logging.getLogger(__name__)


class DataReader:
    """Handles reading XBPM data from files or pickle directories.

    This class provides a unified interface for reading XBPM measurement
    data from two different sources:
    - Text files with optional header metadata
    - Directories containing pickle files

    Attributes:
        prm (Prm): Parameters dataclass containing configuration
            and runtime data.
        data (dict): Dictionary containing parsed measurement data.
    """

    def get_available_beamlines(self):
        """Return a list of available beamlines in the current data source.

        Tries to extract from loaded rawdata, or peeks into the file
        if not loaded.
        """
        # Try to extract from rawdata if already loaded
        if hasattr(self, 'rawdata') and self.rawdata is not None:
            return self._extract_beamlines(self.rawdata)
        # Otherwise, try to peek into the file (HDF5 or text)
        # For HDF5, open file and list /raw_data keys
        if hasattr(self.prm, 'inputfile') and self.prm.inputfile:
            import h5py
            fname = self.prm.inputfile
            if os.path.isfile(fname) and fname.endswith(('.h5', '.hdf5')):
                try:
                    with h5py.File(fname, 'r') as h5f:
                        if 'raw_data' in h5f:
                            return list(h5f['raw_data'].keys())
                except Exception as exc:
                    logger.exception(
                        "Exception occurred while reading available beamlines"
                        " from HDF5: %s", exc)
        # Fallback: return empty list
        return []

    """Handles reading XBPM data from files or pickle directories.

    This class provides a unified interface for reading XBPM measurement
    data from two different sources:
    - Text files with optional header metadata
    - Directories containing pickle files

    Attributes:
        prm (Prm): Parameters dataclass containing configuration
            and runtime data.
        data (dict): Dictionary containing parsed measurement data.
    """

    def __init__(self, prm: Prm, builder: Optional[ParameterBuilder] = None):
        """Initialize DataReader with parameters.

        Args:
            prm (Prm): Parameters dataclass instance.
            builder: Optional ParameterBuilder instance to share state.
        """
        self.prm     = prm
        self.builder = builder or ParameterBuilder(prm)
        self.data    = {}
        self.rawdata = None
        self._hdf5_path = None
        self.analysis_meta = {}

    def read(self, beamline_selector=None) -> dict:
        """Read data from working directory or file using backend modules.

        Returns:
            dict: Parsed measurement data dictionary.
        """
        from .reader_hdf5 import read_hdf5, read_hdf5_analysis_meta
        from .reader_pickle import read_pickle_dir
        from .reader_text import read_text_file

        path = self.prm.workdir
        if os.path.isfile(path):
            lower = (path or '').lower()
            if lower.endswith('.h5') or lower.endswith('.hdf5'):
                self.rawdata = read_hdf5(path, beamline_selector)
                self.analysis_meta = read_hdf5_analysis_meta(path)
            else:
                self.rawdata = read_text_file(path)
                self.analysis_meta = {}
        else:
            self.rawdata = read_pickle_dir(path)
            self.analysis_meta = {}
        return self.data


    def _infer_gridstep_from_grid(self, grid_x, grid_y):
        """Infer gridstep from HDF5 grid datasets when missing."""
        if (getattr(self.prm, 'gridstep', None) not in (None, 0)
            or grid_x is None or grid_y is None):
            return
        try:
            dx = np.min(np.diff(np.sort(grid_x))) if grid_x.size > 1 else None
            dy = np.min(np.diff(np.sort(grid_y))) if grid_y.size > 1 else None
            steps = [v for v in (dx, dy) if v not in (None, 0)]
            if steps:
                self.prm.gridstep = float(min(steps))
        except Exception:
            logger.warning(
                "Failed to infer gridstep from HDF5 grid", exc_info=True
            )

    def _fallback_beamline_from_meta(self, h5file):
        """Populate beamline from meta group or raw_data if still unset."""
        if self.prm.beamline:
            return

        # Try meta group first (backward compatibility)
        if 'meta' in h5file:
            bl = h5file['meta'].attrs.get('beamline')
            if isinstance(bl, (str, bytes)):
                self.prm.beamline = (bl.decode()
                                     if isinstance(bl, bytes) else bl)
                return

        # Try extracting from raw_data/<beamline>/parameters
        if 'raw_data' in h5file:
            import h5py  # type: ignore
            raw_grp = h5file['raw_data']
            for obj in raw_grp.values():
                if isinstance(obj, h5py.Group) and 'parameters' in obj:
                    # Found a beamline group, check its parameters
                    bl = obj['parameters'].attrs.get('beamline')
                    if bl:
                        self.prm.beamline = (bl if isinstance(bl, str)
                                             else bl.decode())
                        return

    def _handle_beamline_selection_file(self, beamline_selector) -> None:
        """Handle beamline selection logic for file-based input."""
        # If beamline still unknown, try selector to avoid terminal prompt
        if beamline_selector and not self.prm.beamline:
            beamlines = self._extract_beamlines_from_header()
            if not beamlines:
                beamlines = self._extract_beamlines_fallback(self.rawdata)

            if len(beamlines) == 1:
                chosen = beamlines[0]
                self.prm.beamline = chosen
                self.builder.prm.beamline = chosen
            elif beamlines:
                selected = beamline_selector(beamlines)
                # If user cancels, pick first to avoid terminal prompt
                chosen = selected or beamlines[0]
                self.prm.beamline = chosen
                self.builder.prm.beamline = chosen

    def _configure_xbpmdist(self) -> None:
        """Configure XBPM distance from source."""
        if self.prm.xbpmdist is None:
            try:
                self.prm.xbpmdist = Config.XBPMDISTS[self.prm.beamline]
            except Exception:
                self.prm.xbpmdist = 1.0
            print("\n WARNING: distance from source to XBPM not provided."
                  f" Using default value: {self.prm.xbpmdist} m")

    def _read_from_directory(self, beamline_selector=None) -> None:
        """Read data from pickle files in a directory."""
        self.rawdata = self._get_pickle_data()[self.prm.skip:]

        # If beamline not set, try provided selector to avoid terminal prompt
        if beamline_selector and not self.prm.beamline:
            beamlines = self._extract_beamlines(self.rawdata)
            if not beamlines:
                beamlines = self._extract_beamlines_fallback(self.rawdata)
            if len(beamlines) == 1:
                chosen = beamlines[0]
                self.prm.beamline = chosen
                self.builder.prm.beamline = chosen
            elif beamlines:
                selected = beamline_selector(beamlines)
                # If user cancels, pick first to avoid terminal prompt
                chosen = selected or beamlines[0]
                self.prm.beamline = chosen
                self.builder.prm.beamline = chosen

        # Enrich parameters (will skip prompt if beamline already set)
        self.prm = self.builder.enrich_from_data(
            self.rawdata,
            selected_beamline=self.prm.beamline,
            beamline_selector=beamline_selector,
        )
        self.data = self._blades_fetch()

    @staticmethod
    def _extract_beamlines(rawdata):
        """Extract unique beamlines from raw data list."""
        try:
            beamlines = set()
            for record in rawdata:
                if not (isinstance(record, (list, tuple)) and len(record) > 0):
                    continue

                header = record[0]

                if isinstance(header, dict):
                    # Beamlines are dict keys (e.g., 'MNC1', 'MNC2', 'CAT')
                    for key in header.keys():
                        if isinstance(key, str):
                            beamlines.add(key)
                elif isinstance(header, (list, tuple)):
                    for item in header:
                        if isinstance(item, str):
                            beamlines.add(item)
            return list(beamlines)
        except Exception:
            return []

    @staticmethod
    def _extract_beamlines_fallback(rawdata):
        """Fallback: gather all header keys/values as beamline candidates."""
        try:
            beamlines = set()
            for record in rawdata:
                if not (isinstance(record, (list, tuple)) and len(record) > 0):
                    continue
                header = record[0]
                if isinstance(header, dict):
                    # Try to get keys first (primary beamline identifiers)
                    for key in header.keys():
                        if isinstance(key, str):
                            beamlines.add(key)
                elif isinstance(header, (list, tuple)):
                    for item in header:
                        if isinstance(item, str):
                            beamlines.add(item)
            return list(beamlines)
        except Exception:
            return []

    def _extract_beamlines_from_header(self):
        """Extract beamline from already parsed header if present."""
        return [self.prm.beamline] if self.prm.beamline else []

    def _get_pickle_data(self) -> list:
        """Open pickle files in directory and extract data.

        Returns:
            list: All data collected from pickle files in working directory.
        """
        allfiles = os.listdir(self.prm.workdir)
        picklefiles = [pf for pf in allfiles if pf.endswith("pickle")]

        if len(picklefiles) == 0:
            print(f"No pickle files found in directory '{self.prm.workdir}'."
                  "Aborting.")
            sys.exit(0)

        sfiles = sorted(picklefiles,
                        key=lambda name: self.builder.lastfield(name, '_'))
        rawdata = []
        for file in sfiles:
            with open(self.prm.workdir + "/" + file, 'rb') as df:
                rawdata.append(pickle.load(df))  # noqa: S301

        return rawdata

    @staticmethod
    def _is_empty(line: str) -> bool:
        """Check if a line is empty or contains only whitespace."""
        return bool(re.match(r'^\s*$', line))

    @staticmethod
    def _is_header(line: str) -> bool:
        """Check if a line is a header/comment line (starts with #)."""
        return bool(re.match(r'^\s*#', line))

    def _parse_header_line(self, line: str) -> None:
        """Extract metadata from a header line.

        Expected format: # Key: value
        """
        cline = line.strip('#')
        # Split only on the first ':' to avoid accidental extra splits
        kprm, vprm = cline.split(':', 1)
        key = kprm.strip().lower()
        val = vprm.strip()

        # Helper to extract a numeric value from strings like "199.86 mA"
        def _extract_float(text: str) -> float:
            m = re.search(r"[-+]?\d+(?:\.\d+)?(?:[eE][-+]?\d+)?",
                          text.strip())
            if not m:
                raise ValueError(f"Could not parse float from '{text}'")
            return float(m.group(0))

        if re.search(r'current', key, re.IGNORECASE):
            self.prm.current = _extract_float(val)
        elif re.search(r'beamline', key, re.IGNORECASE):
            blval = val
            # Prefer code inside parentheses, e.g., "Caterete (CAT)" -> "CAT"
            m = re.search(r"\(([^)]+)\)", blval)
            if m:
                self.prm.beamline = m.group(1).strip().upper()
            else:
                # Try to find the beamline code by looking up the full name
                try:
                    self.prm.beamline = self.builder.found_key(
                        Config.BEAMLINENAME, blval.strip()
                        )
                except StopIteration:
                    # Fallback: if exact match not found, keep original
                    self.prm.beamline = blval
        elif re.search(r'gap', key, re.IGNORECASE):
            self.prm.phaseorgap = val
        elif re.search(r'xbpm', key, re.IGNORECASE):
            self.prm.xbpmdist = _extract_float(val)
        elif re.search(r'inter bpm', key, re.IGNORECASE):
            self.prm.bpmdist = _extract_float(val)
        else:
            self.prm[key] = val

    def _parse_data_line(self, line: str) -> None:
        """Parse a data line and add it to the data dictionary.

        Expected format: nom_x nom_y to err_to ti err_ti bi err_bi bo err_bo
        """
        parts = line.strip().split()
        key = (float(parts[0]), float(parts[1]))
        self.data[key] = np.array([
            [float(parts[ii]), float(parts[ii + 1])]
            for ii in range(2, len(parts), 2)
        ])

    def _infer_gridstep(self) -> None:
        """Infer grid step from data keys if not explicitly provided."""
        try:
            xs = np.unique([k[0] for k in self.data.keys()])
            ys = np.unique([k[1] for k in self.data.keys()])
            dx = np.min(np.diff(np.sort(xs))) if xs.size > 1 else None
            dy = np.min(np.diff(np.sort(ys))) if ys.size > 1 else None
            steps = [v for v in (dx, dy) if v not in (None, 0)]
            if steps:
                self.prm.gridstep = float(min(steps))
        except Exception as err:
            print(f"\nWARNING: could not infer grid step from data: {err}.")

    def _print_summary(self) -> None:
        """Print a summary of the loaded data and parameters."""
        bl = self.prm.beamline or "N/A"
        blname = Config.BEAMLINENAME[bl[:3]]
        xbpm_str = f"{self.prm.xbpmdist} m" if self.prm.xbpmdist else "N/A"
        bpm_str  = f"{self.prm.bpmdist} m" if self.prm.bpmdist else "N/A"

        print(f"""
### Working beamline:\t   {blname} ({bl})
### Storage ring current : {self.prm.current}
### Grid step:             {self.prm.gridstep}
### Distance source-XBPM : {xbpm_str}
### Distance between BPMs: {bpm_str}
### Gap or phase:          {self.prm.phaseorgap}
"""
)

    def _blades_fetch(self) -> dict:
        """Retrieve each blade's data and average over their values."""
        data = dict()
        beamline = self.prm.beamline

        for dt in self.rawdata:
            try:
                xbpm = dt[0][beamline]
                vals = list()
                for blade in Config.BLADEMAP[beamline].values():
                    av, sd = self._blade_average(xbpm[f'{blade}_val'])
                    vals.append((av, sd))
                bpm_x = dt[2]['agx']
                bpm_y = dt[2]['agy']
                data[bpm_x, bpm_y] = np.array(vals)
            except Exception as err:
                print("\n WARNING: when fetching blades' values and averaging:"
                      f" {err}\n")
        return data

    def _blade_average(self, blade):
        """Calculate the average of blades' values for current beamline."""
        if self.prm.beamline in ["MGN", "MNC"]:
            return np.average(blade), np.std(blade)

        vals = np.array([
            vv * Config.AMPSUB[un] for vv, un in blade
        ])
        return np.average(vals), np.std(vals)

    def load_figures_from_hdf5(self, hdf5_path: str = None) -> dict:
        """Load and reconstruct figures from HDF5 file.

        Parameters
        ----------
        hdf5_path : str, optional
            Path to HDF5 file. If None, uses self._hdf5_path.

        Returns:
            dict: Dictionary with reconstructed figures, or empty dict if
                  no figures exist in the file.
        """
        try:
            import h5py  # type: ignore
        except Exception as exc:  # pragma: no cover - env dependent
            raise RuntimeError(
                "h5py is required to load figures from HDF5 files."
                "Please install it"
            ) from exc

        path = hdf5_path or self._hdf5_path
        if not path:
            return {}

        results = {}

        # Load analysis metadata up front (scales, BPM stats, sweeps fits)
        try:
            with h5py.File(path, 'r') as h5:
                self._load_hdf5_analysis_meta(h5)
        except Exception:  # pragma: no cover - defensive
            logger.exception("Failed to load analysis metadata from HDF5")

        # Map HDF5 figure names to result dictionary keys
        figure_map = {
            'blade_map': 'blade_figure',
            'sweeps': 'sweeps_figure',
            'blades_center': 'blades_center_figure',
            'blades_at_sweeps': 'blades_center_figure',
            'blades_sweeps': 'blades_center_figure',
            'xbpm_raw_positions': 'xbpm_raw_pairwise_figure',
            'xbpm_scaled_positions': 'xbpm_scaled_pairwise_figure',
            'bpm_positions': 'bpm_figure',
            'bpm': 'bpm_figure',
        }

        # Additional variants for position figures
        position_variants = [
            ('xbpm_raw_pairwise', 'xbpm_raw_pairwise_figure'),
            ('xbpm_raw_cross', 'xbpm_raw_cross_figure'),
            ('xbpm_scaled_pairwise', 'xbpm_scaled_pairwise_figure'),
            ('xbpm_scaled_cross', 'xbpm_scaled_cross_figure'),
        ]

        for hdf5_name, result_key in figure_map.items():
            try:
                fig = reconstruct_figure_from_hdf5(path, hdf5_name)
                if fig is not None:
                    results[result_key] = fig
                    logger.info("Loaded figure: %s", hdf5_name)
            except (ValueError, KeyError) as exc:
                logger.debug(
                    "Figure %s not found in HDF5",
                    hdf5_name,
                    exc_info=exc,
                )

        # Try loading position variants
        for hdf5_name, result_key in position_variants:
            try:
                fig = reconstruct_figure_from_hdf5(path, hdf5_name)
                if fig is not None:
                    results[result_key] = fig
                    logger.info("Loaded figure: %s", hdf5_name)
            except (ValueError, KeyError) as exc:
                logger.debug(
                    "Figure %s not found in HDF5",
                    hdf5_name,
                    exc_info=exc,
                )

        return results


def _find_analysis_group(h5_file):
    """Find analysis group, prefer analysis_<beamline> over legacy/analysis."""
    # First try to find analysis_<beamline> variants
    for key in h5_file.keys():
        if key.startswith('analysis_'):
            return h5_file[key]
    # Fall back to legacy /analysis
    if 'analysis' in h5_file:
        return h5_file['analysis']
    return None


def reconstruct_figure_from_hdf5(h5_file, figure_name: str):
    """Reconstruct matplotlib figure from stored HDF5 data.

    Args:
        h5_file: Open h5py.File object or path to HDF5 file.
        figure_name: Name of figure to reconstruct. Options:
            - 'blade_map': Blade intensity heatmaps (2x2 subplots)
            - 'sweeps': Central horizontal/vertical sweeps
            - 'blades_center': Blade currents at center
            - 'xbpm_raw_pairwise': Raw XBPM pairwise position comparison
            - 'xbpm_raw_cross': Raw XBPM cross-blade position comparison
            - 'xbpm_scaled_pairwise': Scaled XBPM pairwise position comparison
            - 'xbpm_scaled_cross': Scaled XBPM cross-blade position comparison
            - 'bpm_positions': BPM position comparison

            Legacy names (still supported):
            - 'xbpm_raw_positions': Same as xbpm_raw_pairwise
            - 'xbpm_scaled_positions': Same as xbpm_scaled_pairwise

    Returns:
        matplotlib.figure.Figure: Reconstructed figure.

    Example:
        >>> import h5py
        >>> with h5py.File('analysis.h5', 'r') as h5:
        ...     fig = reconstruct_figure_from_hdf5(h5, 'sweeps')
        ...     fig.savefig('sweeps_reconstructed.png')
    """
    try:
        import h5py
    except ImportError as exc:
        raise RuntimeError("h5py required for figure reconstruction") from exc

    # Handle file path or file object
    if isinstance(h5_file, str):
        with h5py.File(h5_file, 'r') as h5:
            return reconstruct_figure_from_hdf5(h5, figure_name)

    # Try to find analysis group: prefer analysis_<beamline>,
    # fall back to legacy
    analysis_grp = _find_analysis_group(h5_file)
    if analysis_grp is None:
        raise ValueError("No /analysis* group found in HDF5 file")

    # Dispatch to reconstruction functions that read from /analysis/
    if figure_name == 'blade_map':
        return _reconstruct_blade_map(analysis_grp)
    elif figure_name == 'sweeps':
        return _reconstruct_sweeps(analysis_grp)
    elif figure_name == 'blades_center':
        return _reconstruct_blades_center(analysis_grp)
    else:
        # Handle all position figure types
        # For pairwise/cross/bpm, use figure_name directly as dataset name
        # For legacy names, map to base types
        legacy_map = {
            'xbpm_raw_positions': 'xbpm_raw',
            'xbpm_scaled_positions': 'xbpm_scaled',
            'bpm_positions': 'bpm',
        }

        # If it's a legacy name, use the mapped name, otherwise use
        # figure_name as-is
        dataset_name = legacy_map.get(figure_name, figure_name)

        # Validate figure name
        valid_names = ['xbpm_raw_pairwise', 'xbpm_raw_cross',
                      'xbpm_scaled_pairwise', 'xbpm_scaled_cross',
                      'bpm_positions', 'bpm', 'xbpm_raw', 'xbpm_scaled']
        if dataset_name not in valid_names:
            available = ['blade_map', 'sweeps', 'blades_center'] + valid_names
            raise ValueError(
                f"Unknown figure '{figure_name}'. Available: {available}"
            )

        return _reconstruct_positions(analysis_grp, dataset_name)


def _reconstruct_blade_map(analysis_grp):
    """Reconstruct blade intensity map from /analysis/blade_map/."""
    from .visualizers import BladeMapVisualizer

    if 'blade_map' not in analysis_grp:
        raise ValueError("No blade_map in /analysis/ group")

    return BladeMapVisualizer.plot_from_hdf5(analysis_grp['blade_map'])


def _reconstruct_sweeps(analysis_grp):
    """Reconstruct central sweeps from /analysis/ sweeps group.

    Accepts current name "sweeps" and legacy variants if present.
    """
    from .visualizers import SweepVisualizer

    sweeps_grp = (
        analysis_grp.get('sweeps') or
        analysis_grp.get('sweep') or
        analysis_grp.get('central_sweeps')
    )

    if sweeps_grp is None:
        raise ValueError("No sweeps in /analysis/ group")

    # Accept legacy dataset names as fallbacks
    h_data = (
        sweeps_grp.get('blades_h') or
        sweeps_grp.get('h_sweep') or
        sweeps_grp.get('horizontal')
    ) if sweeps_grp else None

    v_data = (
        sweeps_grp.get('blades_v') or
        sweeps_grp.get('v_sweep') or
        sweeps_grp.get('vertical')
    ) if sweeps_grp else None

    # Heuristic fallback: pick datasets by their fields if names differ
    if sweeps_grp is not None:
        for _, ds in sweeps_grp.items():
            if h_data is None and 'x_index' in ds.dtype.names:
                h_data = ds
            if v_data is None and 'y_index' in ds.dtype.names:
                v_data = ds
            if h_data is not None and v_data is not None:
                break

    # If neither dataset exists, indicate missing data
    if h_data is None and v_data is None:
        raise ValueError("No sweeps datasets found in sweeps group")

    return SweepVisualizer.plot_from_hdf5(h_data, v_data)


def _reconstruct_blades_center(analysis_grp):
    """Reconstruct blade currents at center from /analysis/sweeps/."""
    from .visualizers import BladeCurrentVisualizer

    if 'sweeps' not in analysis_grp:
        raise ValueError("No sweeps in /analysis/ group")

    sweeps_grp = analysis_grp['sweeps']
    h_data = sweeps_grp.get('blades_h')
    v_data = sweeps_grp.get('blades_v')

    return BladeCurrentVisualizer.plot_from_hdf5(h_data, v_data)


def _reconstruct_positions(analysis_grp, dataset_name):
    """Reconstruct position comparison figure from /analysis/positions/.

    Args:
        analysis_grp: HDF5 /analysis/ group
        dataset_name: Dataset name in /analysis/positions/
                     (e.g., 'xbpm_raw_pairwise', 'xbpm_scaled_cross', 'bpm')

    Returns:
        matplotlib figure with 3 subplots (full grid, ROI, RMS differences)
    """
    from .visualizers import PositionVisualizer

    if 'positions' not in analysis_grp:
        raise ValueError("No positions in /analysis/ group")

    positions_grp = analysis_grp['positions']

    if dataset_name not in positions_grp:
        raise ValueError(f"No {dataset_name} in /analysis/positions/")

    return PositionVisualizer.plot_from_hdf5(positions_grp[dataset_name])
